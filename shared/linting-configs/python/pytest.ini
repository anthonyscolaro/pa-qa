[tool:pytest]
# Pytest Configuration for PA-QA Python Projects
# Comprehensive testing configuration with coverage and quality integration

# Minimum pytest version
minversion = 7.0

# Test discovery
testpaths = tests
python_files = 
    test_*.py
    *_test.py
    tests.py
python_classes = 
    Test*
    *Tests
python_functions = 
    test_*

# Default command line options
addopts = 
    # Strict configuration
    --strict-markers
    --strict-config
    
    # Coverage reporting
    --cov=src
    --cov=app
    --cov-report=term-missing:skip-covered
    --cov-report=html:htmlcov
    --cov-report=xml:coverage.xml
    --cov-report=json:coverage.json
    --cov-fail-under=80
    --cov-branch
    
    # Output formatting
    --tb=short
    --show-capture=no
    -ra
    --disable-warnings
    
    # Performance
    --maxfail=3
    --timeout=300
    
    # Parallel execution (uncomment to enable)
    # -n auto
    
    # Verbose output for CI
    # -v

# Test markers for categorization
markers =
    # Test types
    unit: Unit tests - test individual functions/classes
    integration: Integration tests - test component interactions
    e2e: End-to-end tests - test complete workflows
    functional: Functional tests - test business requirements
    acceptance: Acceptance tests - test user stories
    
    # Performance markers
    slow: Tests that take more than 5 seconds
    performance: Performance and load tests
    benchmark: Benchmark tests for performance measurement
    
    # Framework specific
    fastapi: FastAPI specific tests
    django: Django specific tests
    flask: Flask specific tests
    
    # External dependencies
    database: Tests requiring database connection
    redis: Tests requiring Redis connection
    external: Tests requiring external services/APIs
    network: Tests requiring network access
    
    # Security and compliance
    security: Security-related tests
    auth: Authentication and authorization tests
    privacy: Privacy and data protection tests
    
    # Environment specific
    local: Tests that only run locally
    ci: Tests that run in CI/CD
    production: Tests for production environment
    
    # Experimental features
    experimental: Tests for experimental features
    wip: Work in progress tests (may fail)
    
    # Skip conditions
    skip_ci: Skip in CI environment
    skip_local: Skip in local environment
    skip_windows: Skip on Windows
    skip_mac: Skip on macOS
    skip_linux: Skip on Linux

# Async support
asyncio_mode = auto

# Timeout configuration
timeout = 300
timeout_method = thread

# Warning filters
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::ImportWarning
    ignore::ResourceWarning
    # Django specific warnings
    ignore::django.utils.deprecation.RemovedInDjango50Warning
    ignore::django.utils.deprecation.RemovedInDjango41Warning
    # FastAPI specific warnings
    ignore::fastapi.deprecations.FastAPIDeprecationWarning
    # Async warnings
    ignore::trio.TrioDeprecationWarning
    ignore::pytest_asyncio.DeprecationWarning

# Django configuration
DJANGO_SETTINGS_MODULE = config.settings.test

# Test environment variables
env = 
    TESTING = true
    DEBUG = false
    ENVIRONMENT = test
    DATABASE_URL = sqlite:///test.db
    REDIS_URL = redis://localhost:6379/1
    CELERY_TASK_ALWAYS_EAGER = true
    CELERY_TASK_EAGER_PROPAGATES = true

# Logging configuration
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] [%(name)s] %(message)s (%(filename)s:%(lineno)d)
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests/logs/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] [%(name)s] %(message)s (%(filename)s:%(lineno)d)
log_file_date_format = %Y-%m-%d %H:%M:%S

# Test collection optimization
collect_ignore = [
    "setup.py",
    "conftest.py",
    "migrations",
    "venv",
    ".venv", 
    "build",
    "dist",
    ".git",
    ".tox",
    "node_modules",
    "static",
    "media",
]

# Doctest configuration
doctest_optionflags = 
    NORMALIZE_WHITESPACE
    IGNORE_EXCEPTION_DETAIL
    ELLIPSIS

# Console output
console_output_style = progress

# Test session configuration
required_plugins = 
    pytest-cov
    pytest-mock
    pytest-asyncio

# JUnit XML configuration (for CI/CD)
junit_suite_name = pa-qa-test-suite
junit_logging = system-out
junit_log_passing_tests = true
junit_duration_report = total

# Performance optimization
cache_dir = .pytest_cache

# Xdist configuration (for parallel execution)
# Uncomment to enable parallel testing
# [tool:pytest-xdist]
# addopts = -n auto --dist=loadfile

# Coverage configuration integration
[coverage:run]
source = src, app
omit = 
    */migrations/*
    */venv/*
    */virtualenvs/*
    */tests/*
    */test_*
    manage.py
    setup.py
    conftest.py
    */__init__.py
    */settings/*
    */config/*
branch = true
parallel = true

[coverage:report]
precision = 2
show_missing = true
skip_covered = false
sort = Cover
exclude_lines =
    pragma: no cover
    def __repr__
    def __str__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod
    # Django specific exclusions
    def get_absolute_url
    def __unicode__
    # FastAPI specific exclusions
    @app.exception_handler
    if settings.DEBUG

[coverage:html]
directory = htmlcov
title = PA-QA Test Coverage Report

[coverage:xml]
output = coverage.xml

[coverage:json]
output = coverage.json
pretty_print = true